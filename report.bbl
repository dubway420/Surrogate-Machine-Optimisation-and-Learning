\begin{thebibliography}{10}

\bibitem{ahmed1986seismic}
K.~Ahmed, J.~Parker, and D.~Proffitt.
\newblock Seismic response of the advanced gas cooled reactor core.
\newblock {\em Nuclear Engineering and Design}, 94(1):67--92, 1986.

\bibitem{ahn2020deep}
J.~Ahn and S.~J. Lee.
\newblock Deep learning-based procedure compliance check system for nuclear
  power plant emergency operation.
\newblock {\em Nuclear Engineering and Design}, 370:110868, 2020.

\bibitem{albawi2017understanding}
S.~Albawi, T.~A. Mohammed, and S.~Al-Zawi.
\newblock Understanding of a convolutional neural network.
\newblock In {\em 2017 International Conference on Engineering and Technology
  (ICET)}, pages 1--6. Ieee, 2017.

\bibitem{allen1990seismic}
C.~Allen.
\newblock Seismic design of the heysham 2 advanced gas cooled reactor nuclear
  power station.
\newblock Technical report, 1990.

\bibitem{asteris2021predicting}
P.~G. Asteris, A.~D. Skentou, A.~Bardhan, P.~Samui, and K.~Pilakoutas.
\newblock Predicting concrete compressive strength using hybrid ensembling of
  surrogate machine learning models.
\newblock {\em Cement and Concrete Research}, 145:106449, 2021.

\bibitem{babu2016deep}
G.~S. Babu, P.~Zhao, and X.-L. Li.
\newblock Deep convolutional neural network based regression approach for
  estimation of remaining useful life.
\newblock In {\em International conference on database systems for advanced
  applications}, pages 214--228. Springer, 2016.

\bibitem{bishop2006pattern}
C.~M. Bishop.
\newblock {\em Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem{blum1982simple}
L.~Blum, M.~Blum, and M.~Shub.
\newblock {\em A simple secure pseudo-random number generator}.
\newblock Electronics Research Laboratory, College of Engineering, University
  of~…, 1982.

\bibitem{branco2017smogn}
P.~Branco, L.~Torgo, and R.~P. Ribeiro.
\newblock Smogn: a pre-processing approach for imbalanced regression.
\newblock In {\em First international workshop on learning with imbalanced
  domains: Theory and applications}, pages 36--50. PMLR, 2017.

\bibitem{bui2016using}
H.~M. Bui, M.~Lech, E.~Cheng, K.~Neville, and I.~S. Burnett.
\newblock Using grayscale images for object recognition with
  convolutional-recursive neural network.
\newblock In {\em 2016 IEEE Sixth International Conference on Communications
  and Electronics (ICCE)}, pages 321--325. IEEE, 2016.

\bibitem{chai2014root}
T.~Chai and R.~R. Draxler.
\newblock Root mean square error (rmse) or mean absolute error (mae).
\newblock {\em Geoscientific Model Development Discussions}, 7(1):1525--1534,
  2014.

\bibitem{de2013decision}
B.~De~Ville.
\newblock Decision trees.
\newblock {\em Wiley Interdisciplinary Reviews: Computational Statistics},
  5(6):448--455, 2013.

\bibitem{deitel2002python}
H.~M. Deitel.
\newblock {\em Python: how to program}.
\newblock Prentice Hall Professional Technical Reference, 2002.

\bibitem{deng2009imagenet}
J.~Deng, W.~Dong, R.~Socher, L.-J. Li, K.~Li, and L.~Fei-Fei.
\newblock Imagenet: A large-scale hierarchical image database.
\newblock In {\em 2009 IEEE conference on computer vision and pattern
  recognition}, pages 248--255. Ieee, 2009.

\bibitem{dihoru2018neural}
L.~Dihoru, M.~Dietz, T.~Horseman, P.~Kloukinas, O.~Oddbjornsson, E.~Voyagaki,
  A.~J. Crewe, and C.~A. Taylor.
\newblock Neural networks for displacement analysis in an advanced gas cooled
  reactor core model.
\newblock {\em Nuclear Engineering and Design}, 332:252--266, 2018.

\bibitem{dihoru2014multi}
L.~Dihoru, O.~Oddbjornsson, T.~Horseman, M.~Dietz, J.~Wilson, P.~Kloukinas,
  E.~Voyagaki, A.~Crewe, and C.~Taylor.
\newblock Multi-layer array rig work for seismic behaviour with cracked bricks.
\newblock In {\em The 4th EDF Energy Nuclear Graphite Symposium. Engineering
  Challenges Associated with the Life of Graphite Reactor Cores}, 2014.

\bibitem{dihoru2017development}
L.~Dihoru, O.~Oddbjornsson, P.~Kloukinas, M.~Dietz, T.~Horseman, E.~Voyagaki,
  A.~J. Crewe, C.~A. Taylor, and A.~G. Steer.
\newblock The development of a physical model of an advanced gas cooled reactor
  core: Outline of the feasibility study.
\newblock {\em Nuclear Engineering and Design}, 323:269--279, 2017.

\bibitem{dozat2016incorporating}
T.~Dozat.
\newblock Incorporating nesterov momentum into adam.
\newblock 2016.

\bibitem{dwarampudi2019effects}
M.~Dwarampudi and N.~Reddy.
\newblock Effects of padding on lstms and cnns.
\newblock {\em arXiv preprint arXiv:1903.07288}, 2019.

\bibitem{elsworth2020time}
S.~Elsworth and S.~G{\"u}ttel.
\newblock Time series forecasting using lstm networks: A symbolic approach.
\newblock {\em arXiv preprint arXiv:2003.05672}, 2020.

\bibitem{fernandez2017nuclear}
M.~G. Fernandez, A.~Tokuhiro, K.~Welter, and Q.~Wu.
\newblock Nuclear energy system’s behavior and decision making using machine
  learning.
\newblock {\em Nuclear Engineering and Design}, 324:27--34, 2017.

\bibitem{gomez2020status}
M.~Gomez-Fernandez, K.~Higley, A.~Tokuhiro, K.~Welter, W.-K. Wong, and H.~Yang.
\newblock Status of research and development of learning-based approaches in
  nuclear science and engineering: A review.
\newblock {\em Nuclear Engineering and Design}, 359:110479, 2020.

\bibitem{grundgeiger2018programming}
D.~Grundgeiger.
\newblock {\em Programming Visual Basic. NET}.
\newblock O'Reilly, 2018.

\bibitem{gurney1997introduction}
K.~Gurney.
\newblock {\em An introduction to neural networks}.
\newblock CRC press, 1997.

\bibitem{hansen2015tiny}
L.~Hansen.
\newblock Tiny imagenet challenge submission.
\newblock {\em CS 231N}, 2015.

\bibitem{hara2015analysis}
K.~Hara, D.~Saito, and H.~Shouno.
\newblock Analysis of function of rectified linear unit used in deep learning.
\newblock In {\em 2015 international joint conference on neural networks
  (IJCNN)}, pages 1--8. IEEE, 2015.

\bibitem{harris2020array}
C.~R. Harris, K.~J. Millman, S.~J. Van Der~Walt, R.~Gommers, P.~Virtanen,
  D.~Cournapeau, E.~Wieser, J.~Taylor, S.~Berg, N.~J. Smith, et~al.
\newblock Array programming with numpy.
\newblock {\em Nature}, 585(7825):357--362, 2020.

\bibitem{hawkins2004problem}
D.~M. Hawkins.
\newblock The problem of overfitting.
\newblock {\em Journal of chemical information and computer sciences},
  44(1):1--12, 2004.

\bibitem{he2015deep}
K.~He, X.~Zhang, S.~Ren, and J.~Sun.
\newblock Deep residual learning for image recognition. corr abs/1512.03385
  (2015), 2015.

\bibitem{hecht1992theory}
R.~Hecht-Nielsen.
\newblock Theory of the backpropagation neural network.
\newblock In {\em Neural networks for perception}, pages 65--93. Elsevier,
  1992.

\bibitem{henderson1995job}
R.~L. Henderson.
\newblock Job scheduling under the portable batch system.
\newblock In {\em Workshop on Job Scheduling Strategies for Parallel
  Processing}, pages 279--294. Springer, 1995.

\bibitem{huber1964robust}
P.~J. Huber.
\newblock Robust estimation of a location parameter: Annals mathematics
  statistics, 35.
\newblock 1964.

\bibitem{ibrahim2016overview}
D.~Ibrahim.
\newblock An overview of soft computing.
\newblock {\em Procedia Computer Science}, 102:34--38, 2016.

\bibitem{javadi2003neural}
A.~Javadi, T.~Tan, and M.~Zhang.
\newblock Neural network for constitutive modelling in finite element analysis.
\newblock {\em Computer Assisted Mechanics and Engineering Sciences},
  10(4):523--530, 2003.

\bibitem{johnson2019survey}
J.~M. Johnson and T.~M. Khoshgoftaar.
\newblock Survey on deep learning with class imbalance.
\newblock {\em Journal of Big Data}, 6(1):1--54, 2019.

\bibitem{Jones2018}
H.~R. Jones.
\newblock Surrogate machine optimisation and learning.
\newblock \url{https://gitlab.cs.man.ac.uk/q59494hj/parmec_agr_ml_surrogate},
  2018.

\bibitem{huw_rhys_jones_2022_6967536}
H.~R. Jones.
\newblock {Surrogate Machine Learning for Parmec Advanced Gas-cooled Reactor
  (AGR) Analysis}.
\newblock \url{https://doi.org/10.5281/zenodo.6967536}, Aug. 2022.

\bibitem{jones2022surrogate}
H.~R. Jones, T.~Mu, D.~Kudawoo, G.~Brown, P.~Martinuzzi, and N.~McLachlan.
\newblock A surrogate machine learning model for advanced gas-cooled reactor
  graphite core safety analysis.
\newblock {\em Nuclear Engineering and Design}, 395:111842, 2022.

\bibitem{kalman1992tanh}
B.~L. Kalman and S.~C. Kwasny.
\newblock Why tanh: choosing a sigmoidal function.
\newblock In {\em [Proceedings 1992] IJCNN International Joint Conference on
  Neural Networks}, volume~4, pages 578--581. IEEE, 1992.

\bibitem{ketkar2017introduction}
N.~Ketkar.
\newblock Introduction to keras.
\newblock In {\em Deep learning with Python}, pages 97--111. Springer, 2017.

\bibitem{ketkar2017stochastic}
N.~Ketkar.
\newblock Stochastic gradient descent.
\newblock In {\em Deep learning with Python}, pages 113--132. Springer, 2017.

\bibitem{kim2019machine}
S.~H. Kim and F.~Boukouvala.
\newblock Machine learning-based surrogate modeling for data-driven
  optimization: a comparison of subset selection for regression techniques.
\newblock {\em Optimization Letters}, pages 1--22, 2019.

\bibitem{wiki:xxx}
T.~Koziara.
\newblock Parmec documentation, 2019.
\newblock [Online; accessed 19-November-2020].

\bibitem{kralj2007seismic}
B.~Kralj, S.~Humphreys, and B.~Duncan.
\newblock Seismic modelling of an agr nuclear reactor core.
\newblock {\em SPECIAL PUBLICATION-ROYAL SOCIETY OF CHEMISTRY}, 309:193, 2007.

\bibitem{lewkowycz2021decay}
A.~Lewkowycz.
\newblock How to decay your learning rate.
\newblock {\em arXiv preprint arXiv:2103.12682}, 2021.

\bibitem{li2015depth}
B.~Li, C.~Shen, Y.~Dai, A.~Van Den~Hengel, and M.~He.
\newblock Depth and surface normal estimation from monocular images using
  regression on deep features and hierarchical crfs.
\newblock In {\em Proceedings of the IEEE conference on computer vision and
  pattern recognition}, pages 1119--1127, 2015.

\bibitem{liang2018deep}
L.~Liang, M.~Liu, C.~Martin, and W.~Sun.
\newblock A deep learning approach to estimate stress distribution: a fast and
  accurate surrogate of finite-element analysis.
\newblock {\em Journal of The Royal Society Interface}, 15(138):20170844, 2018.

\bibitem{liao2016importance}
Z.~Liao and G.~Carneiro.
\newblock On the importance of normalisation layers in deep learning with
  piecewise linear activation units.
\newblock In {\em 2016 IEEE Winter Conference on Applications of Computer
  Vision (WACV)}, pages 1--8. IEEE, 2016.

\bibitem{meyer1997object}
B.~Meyer.
\newblock {\em Object-oriented software construction}, volume~2.
\newblock Prentice hall Englewood Cliffs, 1997.

\bibitem{navada2011overview}
A.~Navada, A.~N. Ansari, S.~Patil, and B.~A. Sonkamble.
\newblock Overview of use of decision tree algorithms in machine learning.
\newblock In {\em 2011 IEEE control and system graduate research colloquium},
  pages 37--42. IEEE, 2011.

\bibitem{nonbol1996description}
E.~Nonb{\o}l.
\newblock Description of the advanced gas cooled type of reactor (agr).
\newblock Technical report, Nordisk Kernesikkerhedsforskning, 1996.

\bibitem{nyshadham2019machine}
C.~Nyshadham, M.~Rupp, B.~Bekker, A.~V. Shapeev, T.~Mueller, C.~W. Rosenbrock,
  G.~Cs{\'a}nyi, D.~W. Wingate, and G.~L. Hart.
\newblock Machine-learned multi-system surrogate models for materials
  prediction.
\newblock {\em npj Computational Materials}, 5(1):1--6, 2019.

\bibitem{oddbjornsson2017physical}
O.~Oddbjornsson, P.~Kloukinas, L.~Dihoru, M.~Dietz, T.~Horseman, E.~Voyagaki,
  A.~Crewe, C.~Taylor, and A.~Steer.
\newblock Physical modelling and testing of an advanced gas cooled reactor core
  model.
\newblock In {\em 16th World Conference on Earthquake Engineering}, 2017.

\bibitem{pedregosa2011scikit}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, et~al.
\newblock Scikit-learn: Machine learning in python.
\newblock {\em the Journal of machine Learning research}, 12:2825--2830, 2011.

\bibitem{perez2017effectiveness}
L.~Perez and J.~Wang.
\newblock The effectiveness of data augmentation in image classification using
  deep learning.
\newblock {\em arXiv preprint arXiv:1712.04621}, 2017.

\bibitem{refaeilzadeh2009cross}
P.~Refaeilzadeh, L.~Tang, and H.~Liu.
\newblock Cross-validation.
\newblock {\em Encyclopedia of database systems}, 5:532--538, 2009.

\bibitem{ruder2016overview}
S.~Ruder.
\newblock An overview of gradient descent optimization algorithms.
\newblock {\em arXiv preprint arXiv:1609.04747}, 2016.

\bibitem{russakovsky2015imagenet}
O.~Russakovsky, J.~Deng, H.~Su, J.~Krause, S.~Satheesh, S.~Ma, Z.~Huang,
  A.~Karpathy, A.~Khosla, M.~Bernstein, et~al.
\newblock Imagenet large scale visual recognition challenge.
\newblock {\em International journal of computer vision}, 115(3):211--252,
  2015.

\bibitem{sarullo2019class}
A.~Sarullo and T.~Mu.
\newblock On class imbalance and background filtering in visual relationship
  detection.
\newblock In {\em 2019 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--8. IEEE, 2019.

\bibitem{seger2018investigation}
C.~Seger.
\newblock An investigation of categorical variable encoding techniques in
  machine learning: binary versus one-hot and feature hashing, 2018.

\bibitem{sherstinsky2020fundamentals}
A.~Sherstinsky.
\newblock Fundamentals of recurrent neural network (rnn) and long short-term
  memory (lstm) network.
\newblock {\em Physica D: Nonlinear Phenomena}, 404:132306, 2020.

\bibitem{shorten2019survey}
C.~Shorten and T.~M. Khoshgoftaar.
\newblock A survey on image data augmentation for deep learning.
\newblock {\em Journal of Big Data}, 6(1):1--48, 2019.

\bibitem{simonyan2014very}
K.~Simonyan and A.~Zisserman.
\newblock Very deep convolutional networks for large-scale image recognition.
\newblock {\em arXiv preprint arXiv:1409.1556}, 2014.

\bibitem{smola2004tutorial}
A.~J. Smola and B.~Sch{\"o}lkopf.
\newblock A tutorial on support vector regression.
\newblock {\em Statistics and computing}, 14(3):199--222, 2004.

\bibitem{srivastava2014dropout}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov.
\newblock Dropout: a simple way to prevent neural networks from overfitting.
\newblock {\em The journal of machine learning research}, 15(1):1929--1958,
  2014.

\bibitem{tan2018survey}
C.~Tan, F.~Sun, T.~Kong, W.~Zhang, C.~Yang, and C.~Liu.
\newblock A survey on deep transfer learning.
\newblock In {\em International conference on artificial neural networks},
  pages 270--279. Springer, 2018.

\bibitem{torrey2010transfer}
L.~Torrey and J.~Shavlik.
\newblock Transfer learning.
\newblock In {\em Handbook of research on machine learning applications and
  trends: algorithms, methods, and techniques}, pages 242--264. IGI global,
  2010.

\bibitem{voyagaki2018earthquake}
E.~Voyagaki, P.~Kloukinas, M.~Dietz, L.~Dihoru, T.~Horseman, O.~Oddbjornsson,
  A.~J. Crewe, C.~A. Taylor, and A.~Steer.
\newblock Earthquake response of a multiblock nuclear reactor graphite core:
  Experimental model vs simulations.
\newblock {\em Earthquake Engineering \& Structural Dynamics},
  47(13):2601--2626, 2018.

\bibitem{wallach1989mean}
D.~Wallach and B.~Goffinet.
\newblock Mean squared error of prediction as a criterion for evaluating and
  comparing system models.
\newblock {\em Ecological modelling}, 44(3-4):299--306, 1989.

\bibitem{wang2022comprehensive}
Q.~Wang, Y.~Ma, K.~Zhao, and Y.~Tian.
\newblock A comprehensive survey of loss functions in machine learning.
\newblock {\em Annals of Data Science}, 9(2):187--212, 2022.

\bibitem{willmott2005advantages}
C.~J. Willmott and K.~Matsuura.
\newblock Advantages of the mean absolute error (mae) over the root mean square
  error (rmse) in assessing average model performance.
\newblock {\em Climate research}, 30(1):79--82, 2005.

\bibitem{xie2015beyond}
Y.~Xie, F.~Xing, X.~Kong, H.~Su, and L.~Yang.
\newblock Beyond classification: structured regression for robust cell
  detection using convolutional neural network.
\newblock In {\em International conference on medical image computing and
  computer-assisted intervention}, pages 358--365. Springer, 2015.

\bibitem{xu2019learning}
Z.~Xu, A.~M. Dai, J.~Kemp, and L.~Metz.
\newblock Learning an adaptive learning rate schedule.
\newblock {\em arXiv preprint arXiv:1909.09712}, 2019.

\bibitem{yang2021delving}
Y.~Yang, K.~Zha, Y.~Chen, H.~Wang, and D.~Katabi.
\newblock Delving into deep imbalanced regression.
\newblock In {\em International Conference on Machine Learning}, pages
  11842--11851. PMLR, 2021.

\bibitem{yao2007early}
Y.~Yao, L.~Rosasco, and A.~Caponnetto.
\newblock On early stopping in gradient descent learning.
\newblock {\em Constructive Approximation}, 26(2):289--315, 2007.

\bibitem{ying2019overview}
X.~Ying.
\newblock An overview of overfitting and its solutions.
\newblock In {\em Journal of physics: Conference series}, volume 1168, page
  022022. IOP Publishing, 2019.

\bibitem{you2019does}
K.~You, M.~Long, J.~Wang, and M.~I. Jordan.
\newblock How does learning rate decay help modern neural networks?
\newblock {\em arXiv preprint arXiv:1908.01878}, 2019.

\bibitem{zeng2018machine}
Y.~Zeng, J.~Liu, K.~Sun, and L.-w. Hu.
\newblock Machine learning based system performance prediction model for
  reactor control.
\newblock {\em Annals of Nuclear Energy}, 113:270--278, 2018.

\bibitem{zheng2015improving}
H.~Zheng, Z.~Yang, W.~Liu, J.~Liang, and Y.~Li.
\newblock Improving deep neural networks using softplus units.
\newblock In {\em 2015 International Joint Conference on Neural Networks
  (IJCNN)}, pages 1--4. IEEE, 2015.

\bibitem{zienkiewicz2005finite}
O.~C. Zienkiewicz, R.~L. Taylor, and J.~Z. Zhu.
\newblock {\em The finite element method: its basis and fundamentals}.
\newblock Elsevier, 2005.

\end{thebibliography}
