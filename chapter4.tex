\chapter{Dataset, Framework, Exploration and Analysis}
\label{cha:dataset}

This chapter has three purposes. Firstly, we explore  the data space using visualisation and statistical techniques. Next, we discuss the machine learning dataset generated using this data. Finally, we discuss the programmatic framework used to generate and manipulate the dataset.

\section{Dataset Exploration and Analysis} \label{data:visualisation}

To help choose a direction for research, a visual inspection of the dataset has been made. As mentioned in subsection~\ref{parmec:output}, the data produced by the Parmec model is multidimensional. Therefore, visual analysis will be made from multiple perspectives. The visualisations have been made possible through the framework that will detailed in the section~\ref{framework}. 

\subsection{Time History: Example Cases}


For a chosen Parmec case, Figures~\ref{fig:time_history_1} and \ref{fig:time_history_2} show the displacement time history for selected channels in two directions. It can be seen that the oscillations in displacement largely follow those of the earthquake acceleration pattern (Figure~\ref{fig:earthquake}). As expected, there is no displacement during the preliminary settle down period up to about 2.5 seconds. Channels near the centre of the core see higher amplitudes, with some of the most central channels also continuing to move after the earthquake has ended at around 8 seconds.  
\\

\noindent
Selecting four time frames from the earthquake time history, it is possible to visualise the displacement in the reactor core at these points. The time frames chosen can be seen in Figure~\ref{fig:earthquake} with vertical indicators and were chosen as they represent the peaks of earthquake acceleration. 
\\

\begin{figure*}[p]
	\centering
	\includegraphics[scale=0.45]{Figures/time_history.png}
	\caption{Time History: Maximum Channel Displacement in the West to East Direction for Sample Channels} {Compare with the earthquake time history (Figure~\ref{fig:earthquake}).}
	\label{fig:time_history_1}
\end{figure*}

\begin{figure*}[p]
	\centering
	\includegraphics[scale=0.45]{Figures/time_history_y.png}
	\caption{Time History: Maximum Channel Displacement in the South to North Direction for Sample Channels } {Compare with the earthquake time history (Figure~\ref{fig:earthquake}).}
	\label{fig:time_history_2}
\end{figure*}

\noindent
A top down view of channel displacements can be seen in Figures~\ref{fig:results1}
and \ref{fig:results2}, where displacements in the west-east and south-north direction can be seen, respectively. For west-east displacement (Figure~\ref{fig:results1}), note that those channels near the edge of the core tend to displace in the opposite direction to those in the centre. For frames 65 and 68, there seems to be little diversity in the distribution of displacement values, whereas for frames 48 and 55 there is more variation, at least for the more central channels. For south-north displacements (Figure~\ref{fig:results2}) the displacements for each case are a variation on a similar pattern in each time frame.
\\

\begin{figure*}[p]
	\centering
	\includegraphics[scale=0.45]{Figures/results1.png}
	\caption{Comparing the Output of Three Cases Through Time: Sum of Channel Displacement in West-East Direction (mm) } { Three cases have been chosen at random from the dataset, corresponding to each of the three columns in this Figure. Each row corresponds to a time index of the earthquake (see the vertical markers in Figure~\ref{fig:earthquake}). The time frame is listed, as well as the earthquake acceleration at that time. The images are a graphical representation of the displacement value for each interstitial channel. Note that values are in the range $ \pm 50 $ i.e. the overall movement of that channel may be up to 50 mm in the left or right direction.}
	\label{fig:results1}
\end{figure*}

\begin{figure*}[p]
	\centering
	\includegraphics[scale=0.45]{Figures/results2.png}
	\caption{Comparing the Output of Three Cases Through Time: Sum of Channel Displacement in South-North Direction (mm) } {Three cases have been chosen at random from the dataset, corresponding to each of the three columns in this Figure. Each row corresponds to a time index of the earthquake (see the vertical markers in Figure~\ref{fig:earthquake}). The time frame is listed, as well as the earthquake acceleration at that time. The images are a graphical representation of the displacement value for each interstitial channel. Note that values are in the range $ \pm 30 $ i.e. the overall movement of that channel may be up to 30 mm in the south or north direction.}
	\label{fig:results2}
\end{figure*}

\noindent
For an alternative view on the previously illustrated example cases, the sum of level-by-level displacement can be seen in Figures~\ref{fig:levels1} and \ref{fig:levels2}. Similar to the top down view equivalent, Figure~\ref{fig:levels1} (west-east displacement) shows little variation across the three sample cases for frames 65 and 68, with slightly more variation on a similar pattern seen in frames 48 and 55. 
\\

\begin{figure*}[p]
	\centering
	\includegraphics[scale=0.6]{Figures/level_results1.png}
	\caption{Comparing Output of Three Cases Through Time: Sum of Level Displacement in West-East Direction (mm) } {Three cases have been chosen at random from the dataset, corresponding to each of the three columns in this Figure. Each row corresponds to a time index of the earthquake (see the vertical markers in Figure~\ref{fig:earthquake}). The time frame is listed. The images are a graphical representation of the displacement value for each interstitial level.}
	\label{fig:levels1}
\end{figure*}

\begin{figure*}[p]
	\centering
	\includegraphics[scale=0.6]{Figures/level_results2.png}
	\caption{Comparing Output of Three Cases Through Time: Sum of Level Displacement in South-North Direction (mm) } { Three cases have been chosen at random from the dataset, corresponding to each of the three columns in this Figure. Each row corresponds to a time index of the earthquake (see the vertical markers in Figure~\ref{fig:earthquake}). The time frame is listed. The images are a graphical representation of the displacement value for each interstitial level.}
	\label{fig:levels2}
\end{figure*}


\subsection{Entire Dataset} \label{data:entire}


Several visualisations were generated based on the entire dataset of approximately 8300 samples. For the time frames highlighted in the previous section, Figures~\ref{fig:histo1} and \ref{fig:histo2} show histograms of all Parmec displacements outputs across all dataset samples. Note that for both displacement directions, the distribution of output values at each time frame fits around a central median value.
\\

\noindent
For a single time frame (48) Figure~\ref{fig:composite} shows a channel by channel summation of the Parmec results across the entire dataset. This allows us to make comparisons between core regions. The outer channels tend to have negative (eastward) displacement, indicated in blue. As we move closer to the centre of the core, the displacement moves towards zero, indicated in white. Moving further towards the centre of the core, the displacement becomes increasingly positive (westward), indicated in red. The displacement values have strong radial symmetry about the centre. The uniform structure of the Parmec outputs in the aforementioned figure are interesting when considering that the input crack patterns are randomly generated.  
\\


\begin{figure*}[p]
	\centering
	\includegraphics[scale=0.15]{Figures/histo1.png}
	\caption{Histogram of Sum Displacement of All Instances: West-East directional displacement } {This plot shows a histogram for results across the dataset. The results for each time frame are Gaussian in shape i.e. a symmetric bell curve around a mean value. However, there seems to be a smaller peak near the left tail.}
	\label{fig:histo1}
\end{figure*}

\begin{figure*}[p]
	\centering
	\includegraphics[scale=0.5]{Figures/histo2.png}
	\caption{Histogram of Sum Displacement of All Instances: South-North directional displacement } {This plot is very similar to Figure~\ref{fig:histo1}. A Gaussian distribution can be seen similarly to the previous plot.}
	\label{fig:histo2}
\end{figure*}

\begin{figure}[ht]
	\centering
	\includegraphics[scale=0.85]{Figures/compositeLines.png}
	\caption{Channel Summation for Time Frame 48 } {For each channel, the Parmec Outputs in the west-east direction were summed.}
	\label{fig:composite}
\end{figure}

\subsection{Output Correlation Analysis} \label{correlation}

\noindent A natural question at this point would be: how do the individual label values from \ref{instance_result_matrix} correlate with each other? For example, do the results for central channels increase when those for outer channels increase? Or is the opposite the case, or neither? \\

\noindent Consider again Figure~\ref{fig:inter_order} which numbers each of the interstitial channels. Note that channels are numbered in rows from left to right and hence numerically close channels are not always physically close - e.g. 75 and 76, which are on opposite ends of the core. Using the numbers from Figure~\ref{fig:inter_order}, consider Figure~\ref{fig:channel_correlations}. It appears that channels which are physically close correlate strongly, with this tendency breaking down the further a two channels are away from each other. This would suggest it may be difficult to train a model capable of making accurate predictions across the whole core.
\\

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{Figures/channels_correlation.png}
	\caption{Correlation of Channel Results Against Each Other}
	\label{fig:channel_correlations}
\end{figure}

\begin{figure}[h]
	\centering
	\includegraphics[scale=0.75]{Figures/central_channel_correlation.png}
	\caption{Correlation of Bricks of the Central Channel (161) Results Against Each Other}
	\label{fig:central_correlations}
\end{figure}


\noindent
Looking closely at only the correlations between results for the central interstitial channel (number 161 - see Figure~\ref{fig:inter_order}), we can again see a stronger correlation the closer two bricks are physically located (Figure~\ref{fig:central_correlations}).

\section{Machine Learning Dataset} \label{dataset}

8300 Parmec instances were generated to form the base dataset. Approximately 75\% of the dataset was randomly partitioned to become the training set (N) with around 6300 instances, with the remaining 25\% (2000 samples) forming the test set ($N_t$).  \\

\noindent
In subsection~\ref{parmec:data}, it was mentioned that the Parmec software can simulate  a core with cracked bricks representing anywhere between 0\%  (intact core) to 100\% (fully cracked) and that fuel bricks in the Parmec model can be modelled as having a single crack, or be double cracked. For the sake of this research, we shall choose a cracking percentage of 40\% and we shall model all cracked bricks as being double cracked. 

\subsection{Model Inputs (Features)} \label{data:inputs}



\begin{figure}[t]
	\centering
	\includegraphics[scale=0.35]{Figures/fuel_channel_numbers.png}
	\caption{Fuel Brick Encoding Order}
	\label{fig:order}
\end{figure}


\noindent
The inputs for the Parmec model also serve as the input features to a machine learning model. The 3-dimensional input structure from Figure~\ref{fig:cascade} is unraveled into a 1-dimensional vector of length 1988. The cracking status of all fuel bricks are encoded according to their level (bottom to top) then by their position as shown in Figure~\ref{fig:order}. Note that at this point we are discarding the empty positions (zeros used to pad the corners). We are also discarding the orientation of the crack and only encoding a fuel brick as uncracked (-1) or cracked (1).
\\

\noindent
With 6300 training samples and 1988 input elements (cracked or uncracked AGR fuel bricks) this gives a matrix of dimensions N by BF (6300 x 1988), hence our feature matrix is defined as $\textbf{X} = \{-1, 1\}^{N \times BF}$. This matrix serves as the base input features to the machine learning models described in the following sections. 


\subsection{Model Outputs (Labels)} \label{data:outputs}

It is expected that part of the output tensor from Parmec (see subsection~\ref{parmec:output}) will become the output labels of surrogate machine learning model i.e. a SMLM will be developed to predict part of the Parmec output tensor. It is unlikely that a single SMLM will be able to accurately predict all of the ouputs from \ref{instance_result_matrix} due to its significant size. Therefore, we will have to narrow the output scope of the model, at least in the short term. We can do this in several ways: 1) We have already explored some research work published in the field of AGR seismic safety analysis (see section~\ref{engineering:literature}), 2) By making a visual and statistical analysis of the data (see section~\ref{data:visualisation})  and 3) through machine learning experimentation such as in section~\ref{prelim:whole}.


\section{Framework} \label{framework}

This section details the programmatic framework \cite{Jones2018} developed during this PhD. This framework was produced in order to streamline the development and optimisation of surrogate machine learning model for this project. The framework is provided free and open source with the intention that other researchers will adapt and use it for their own surrogate machine learning purposes. Using this repository, the accompanying dataset \cite{huw_rhys_jones_2022_6967536} and the attached guide, the method and results presented in this thesis can be reproduced by anyone.
\\

\noindent
The framework is developed so as to be useable on a portable batch system (PBS) as is commonly implemented on university cluster computing systems. These systems allow job queuing and parallel processing of experiments \cite{henderson1995job}. If a PBS system is not available, the framework is functional on any other standard computer.
\\

\noindent
The framework has six principal functions:

\begin{enumerate}
	\item The efficient and reproduceable creation of Parmec data 
	\item The extraction of relevant data from Parmec data cases
	\item The translation and engineering of the aforementioned data into datasets useable for machine learning training or testing 
	\item Machine Learning model design and parameter selection
	\item Model training \& evaluation
	\item Data visualisation and analysis including model performance 
\end{enumerate}

\subsection{Parmec Data Generation}

As mentioned in subsection~\ref{parmec:data}, the industry standard Parmec configuration file generator can only make single instances at a time and to non-reproduceable. As part of the machine learning framework developed for this PhD project, a Parmec case generation tool was developed which allows batch generation of instances, each traceable to a pseudo-random number seed \cite{blum1982simple}. This allows a creation of a large and reproducible dataset. Should the dataset be lost/corrupted or need to be temporarily deleted, it can be exactly reproduced using the original seeds.
\\

\noindent
The tool was developed by adapting an industry standard Microsoft Excel sheet with extensive changes using the Visual Basic .NET framework \cite{grundgeiger2018programming}. Using this tool, the user can batch generate Parmec configuration files by proving a comma seperated file of selected random numbers. 
\\

\subsection{Inputs and Outputs}

\noindent
For ease of use and interaction by the user, the framework converts each Parmec case into a data object, making use the object oriented programming (OOP) paradigm \cite{meyer1997object} with the Python language \cite{deitel2002python}. The Parmec class has interface methods which allow simple access and parsing of the information about that case. An additional layer of abstraction is provided by the creation of additional classes which aggregate all of the Parmec case objects in a batch of cases. This allows then generation of datasets for use in visual analysis or machine learning.
\\

\noindent
The Parmec case class allows the user to access input information about a particular case.  For example, should the user want to get the number of cracks in a particular level of the core. Used in aggregate across all cases within the dataset, the above input feature matrix as described in the previous paragraph can be efficiently obtained. 
\\



\noindent
The large amount of output data generated by Parmec is not in a format readily accessible or interpretable by human users or by other computer analysis. Therefore, the Parmec class object was extended to analyse this data and produce useable outputs. Again, this data is accessible via interactive Parmec object method calls and can be used in aggregate across the entire dataset.
\\

\subsection{Machine Learning Model Design}

The framework allows rapid design of the machine learning model architecture and the selection of parameters. This part of the framework is built upon the existing machine learning frameworks Keras \cite{ketkar2017introduction} and Scikit-learn \cite{pedregosa2011scikit} and also uses the matrix manipulation library Numpy \cite{harris2020array}. A machine learning model can be programmatically generated in a single line of code using the Model class from the framework, which contains arguments for number and types of layers, nodes, activation functions, loss function and learning rate.

\subsection{Machine Learning Model Training and Evaluation}

Once a dataset and base model have been obtained using the framework, it can then be used to train the model and evaluate it.  The model can be automatically retrained a set number of times from randomised starting weights in order to account for the stochastic nature of model training. \\

\noindent 
As part of a single experiment, a batch of differing model architectures or parameters can be selected and the performance of each compared. For instance, we could vary the number of layers of a particular type, then the framework will automatically generate, evaluate  and compare each one, allowing the user to select the optimal arrangement.  \\

\noindent
The framework aids the user in evaluating and comparing trained models through custom callbacks which execute and update the user throughout training using both numerical measures and visual representations of model performance. These include training \& validation loss histories, correlation plots of model prediction against ground truth values and prediction histograms. At the end of training, the framework presents the user with a summary of the experiment  including such values as minimum \& mean model loss, so that the user can make a high level judgement on the performance of parameter selections.

